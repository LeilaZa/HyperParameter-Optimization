# Search Algorithms for Automated Hyper-Parameter Tuning in Machine Learning

This code provides a simple HPO implementation (Grid and Random search) for machine learning models, as described in the paper "Search Algorithms for AutomatedHyper-Parameter Tuning in Machine Learning".  

This paper will help users to improve their machine learning models by optimizing their models' hyper-parameter automatically.

## Paper
Search Algorithms for AutomatedHyper-Parameter Tuning in Machine Learning
[paper link](https://link)  

## Implementation
Sample code for hyper-parameter optimization implementation for machine learning algorithms is provided in this repository.  
  
### Classification problems 
* [Grid-Classification.ipynb](https://github.com/LeilaZa/HyperParameter-Optimization/blob/master/Grid_Classification.ipynb) 

* [Random-Classification.ipynb](https://github.com/LeilaZa/HyperParameter-Optimization/blob/master/Random_Classification.ipynb)   

**Dataset used:** [MIDFIELD](https://engineering.purdue.edu/MIDFIELD)   

### Machine Learning Models 
* Naive Bayes (NB)
* Logistic Regression (LR)
* Decision Tree (DT)
* Random forest (RF)
* Support vector machine (SVM)
* K-nearest neighbor (KNN)  
* XGBoost (XGB)

### HPO Methods Leverages  
* Grid search
* Random search

### Requirements  
* Python 3.7  
* [scikit-learn](https://scikit-learn.org/stable/)  


## Contact-Info
Please dont hesitate to contact me: 
* Email: [lzahe001@fiu.edu](mailto:lzahe001@fiu.edu)
* GitHub: [LeilaZahedi](https://github.com/LeilaZa)
* LinkedIn: [Leila Zahedi](https://www.linkedin.com/in/leilaazahedi/)

## Citation
If this codes helped you in your research, please cite the article:  

Zahedi, L., Mohammadi, F. G., RezaPour, S., Amini, M. H.,(2021). Search Algorithms for AutomatedHyper-Parameter Tuning in Machine Learning. In Computer Science, Computer Engineering, & Applied Computing (pp. 1-10). Springer Nature.

