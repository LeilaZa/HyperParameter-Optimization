# Search Algorithms for Automated Hyper-Parameter Tuning in Machine Learning

This code provides a simple HPO implementation (Grid and Random search) for machine learning models, as described in the paper "Search Algorithms for AutomatedHyper-Parameter Tuning in Machine Learning".  

This paper will help users to improve their machine learning models by optimizing their models' hyper-parameter automatically.

## Paper
Search Algorithms for AutomatedHyper-Parameter Tuning in Machine Learning
[paper link](https://arxiv.org/pdf/2104.14677.pdf)  

## Implementation
Sample code for hyper-parameter optimization implementation for machine learning algorithms is provided in this repository.  
  
### Classification problems 
* [Grid-Classification](https://github.com/LeilaZa/HyperParameter-Optimization/blob/main/MLGridSearch.py) 

* [Random-Classification](https://github.com/LeilaZa/HyperParameter-Optimization/blob/main/MLRandomSearch.py)   

**Dataset used:** [MIDFIELD](https://engineering.purdue.edu/MIDFIELD)   

### Machine Learning Models 
* Naive Bayes (NB)
* Logistic Regression (LR)
* Decision Tree (DT)
* Random forest (RF)
* Support vector machine (SVM)
* K-nearest neighbor (KNN)  
* XGBoost (XGB)

### HPO Methods Leverages  
* Grid search
* Random search

### Requirements  
* Python 3.7  
* [scikit-learn](https://scikit-learn.org/stable/)  


## Contact-Info
Please dont hesitate to contact me: 
* Email: [lzahe001@fiu.edu](mailto:lzahe001@fiu.edu)
* GitHub: [LeilaZahedi](https://github.com/LeilaZa)
* LinkedIn: [Leila Zahedi](https://www.linkedin.com/in/leilaazahedi/)

## Citation
If this codes helped you in your research, please cite the article:  

L. Zahedi, F. G. Mohammadi, S. Rezapour, M. W. Ohland, and M. H.Amini, “Search algorithms for automated hyper-parameter tuning,”The 17th International Conference on Data Science, 2021.

